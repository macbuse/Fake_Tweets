{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "#OK so it's simple and not magic but it works\n",
    "hashtag_regex = re.compile(r'\\#(\\w*)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "NBC News is publishing its database of more than 200,000 tweets that Twitter has tied to \"malicious activity\" from Russia-linked accounts during the 2016 U.S. presidential election.\n",
    "\n",
    "\n",
    "https://developers.slashdot.org/story/18/02/17/0038251/nbc-publishes-200000-tweets-tied-to-russian-trolls\n",
    "\n",
    "\n",
    "\n",
    "The original file has some junk in it which we have to delete before opening with Pandas :\n",
    "\n",
    "Tweets from confirmed Russian trolls, shows only username, timestamp (in UTC), tweet text, and number of times tweet was retweeted and favorited according to our data\",,,,,,,,,,,,,,,,,\n",
    "\n",
    "From NBC News' story: https://www.nbcnews.com/tech/social-media/now-available-more-200-000-deleted-russian-troll-tweets-n844731,,,,,,,,,,,,,,,,,\n",
    "\n",
    "\"If you publish using the data, please credit NBC News and include a link to this page. Send questions to ben.popken@nbcuni.com or twitter.com/bpopken.\",,,,,,,,,,,,,,,,,\n",
    "\n",
    "Twitter screenname,Date tweet sent,Tweet text,Times retweeted,Times favorited,,,,,,,,,,,,,\n",
    "\n",
    "ryanmaxwell_1,3/22/2016 18:31,#IslamKills Are you trying to say that there were no terrorist attacks in Europe before refugees were let in?,,,,,,,,,,,,,,,\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal cleanup of the CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp = file('streamlined_tweets.csv','r')\n",
    "print ''.join(fp.readlines()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = file('streamlined_tweets.csv','r')\n",
    "fe = file('fakenews_tweets.csv','w')\n",
    "\n",
    "with fe as piggy:\n",
    "    for L in fp.readlines()[3:]:\n",
    "        piggy.write(L)\n",
    "\n",
    "df = pd.read_csv('fakenews_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so the data now looks OK \n",
    "there are still a few NaNs in the **Tweet text**\n",
    "column but this isn't so important.\n",
    "\n",
    "I decided to rename the columns as it made following examples easier\n",
    "\n",
    "1. everything to lower case\n",
    "1. swap out spaces to underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Twitter screenname Date tweet sent Tweet text Times retweeted Times favorited'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join( list( df.columns.values)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date tweet sent': 'date_tweet_sent',\n",
       " 'Times favorited': 'times_favorited',\n",
       " 'Times retweeted': 'times_retweeted',\n",
       " 'Tweet text': 'tweet_text',\n",
       " 'Twitter screenname': 'twitter_screenname'}"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_mapper = {}\n",
    "for x in df.columns.values[:5]:\n",
    "    rename_mapper[x] = x.lower().replace(' ','_')\n",
    "rename_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['twitter_screenname', 'date_tweet_sent', 'tweet_text',\n",
       "       'times_retweeted', 'times_favorited'], dtype=object)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Do an inplace as this is a fair chunk of data\n",
    "df.rename(index=str, \n",
    "          columns=rename_mapper,\n",
    "          copy=False,\n",
    "          inplace=True)\n",
    "df.columns.values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now we can just run a regex on the column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_raw = re.compile(r'\\#pokemon\\w*', re.IGNORECASE)\n",
    "# for some reason the fancy indexer won't work with NaN \n",
    "# so we have to set a flag to False\n",
    "mask = df.tweet_text.str.contains(ph_raw, na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitter_screenname</th>\n",
       "      <th>date_tweet_sent</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>times_retweeted</th>\n",
       "      <th>times_favorited</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>peterkistner</td>\n",
       "      <td>7/20/2016 12:26</td>\n",
       "      <td>RT @SPIEGELONLINE: In Dänemark hat eine 49-Jäh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36987</th>\n",
       "      <td>puredavie</td>\n",
       "      <td>7/30/2016 15:13</td>\n",
       "      <td>#IHatePokemonGoBecause my husband wants to cal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49204</th>\n",
       "      <td>marianeuberg1</td>\n",
       "      <td>7/20/2016 12:18</td>\n",
       "      <td>RT @SPIEGELONLINE: In Dänemark hat eine 49-Jäh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49362</th>\n",
       "      <td>puredavie</td>\n",
       "      <td>7/30/2016 16:33</td>\n",
       "      <td>RT @DanaGeezus: #IHatePokemonGoBecause  now I ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50021</th>\n",
       "      <td>mr_clampin</td>\n",
       "      <td>8/16/2016 9:39</td>\n",
       "      <td>RT @SuperGeekGirls: One of our stunning @super...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      twitter_screenname  date_tweet_sent  \\\n",
       "2805        peterkistner  7/20/2016 12:26   \n",
       "36987          puredavie  7/30/2016 15:13   \n",
       "49204      marianeuberg1  7/20/2016 12:18   \n",
       "49362          puredavie  7/30/2016 16:33   \n",
       "50021         mr_clampin   8/16/2016 9:39   \n",
       "\n",
       "                                              tweet_text  times_retweeted  \\\n",
       "2805   RT @SPIEGELONLINE: In Dänemark hat eine 49-Jäh...              NaN   \n",
       "36987  #IHatePokemonGoBecause my husband wants to cal...              NaN   \n",
       "49204  RT @SPIEGELONLINE: In Dänemark hat eine 49-Jäh...              NaN   \n",
       "49362  RT @DanaGeezus: #IHatePokemonGoBecause  now I ...              NaN   \n",
       "50021  RT @SuperGeekGirls: One of our stunning @super...              NaN   \n",
       "\n",
       "       times_favorited  Unnamed: 5  Unnamed: 6  Unnamed: 7  Unnamed: 8  \\\n",
       "2805               NaN         NaN         NaN         NaN         NaN   \n",
       "36987              NaN         NaN         NaN         NaN         NaN   \n",
       "49204              NaN         NaN         NaN         NaN         NaN   \n",
       "49362              NaN         NaN         NaN         NaN         NaN   \n",
       "50021              NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "       Unnamed: 9  Unnamed: 10  Unnamed: 11  Unnamed: 12  Unnamed: 13  \\\n",
       "2805          NaN          NaN          NaN          NaN          NaN   \n",
       "36987         NaN          NaN          NaN          NaN          NaN   \n",
       "49204         NaN          NaN          NaN          NaN          NaN   \n",
       "49362         NaN          NaN          NaN          NaN          NaN   \n",
       "50021         NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "       Unnamed: 14  Unnamed: 15  Unnamed: 16  Unnamed: 17  \n",
       "2805           NaN          NaN          NaN          NaN  \n",
       "36987          NaN          NaN          NaN          NaN  \n",
       "49204          NaN          NaN          NaN          NaN  \n",
       "49362          NaN          NaN          NaN          NaN  \n",
       "50021          NaN          NaN          NaN          NaN  "
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[mask][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pokemon Go fans\n",
    "\n",
    "So let's take someone who has tweeted about Pokemon at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subject = df[ df.twitter_screenname == 'traceyhappymom']\n",
    "stuff = subject.tweet_text.values\n",
    "stuff = stuff.reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "set(hashtag_regex.findall(' '.join(stuff)))\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @JohnFPLane: Just spoke to Putin. Fantastic, great guy. Knows a great deal when he sees it. Sold him the White House! #probabletrumpstwe…\n",
      "RT @DoompaAlioompa: #ProbableTrumpsTweets\r\n",
      "I'll be Putin on the Ritz if you don't text back\n",
      "RT @Born_To_DYE: #TrumpsFavoriteHeadline Putin admits: 'Trump is my hero.'\n",
      "RT @WhiteCollarCMDY: #ProbableTrumpsTweets\r\n",
      "Invites go out to Putin, Jong-un, Khomeini, Duterte and Mugabe--poker at my house, winner gets t…\n"
     ]
    }
   ],
   "source": [
    "tp = re.compile('trump',re.IGNORECASE)\n",
    "pp = re.compile('putin',re.IGNORECASE)\n",
    "hp = re.compile('hillary',re.IGNORECASE)\n",
    "sp = re.compile('sanders',re.IGNORECASE)\n",
    "cp = pp\n",
    "mask = subject.tweet_text.str.contains(cp,na=False)\n",
    "print '\\n'.join(subject[mask].tweet_text.values.reshape((-1,)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough Analysis\n",
    "\n",
    "This is just screwing around to see what is in the file.\n",
    "\n",
    "### Todo\n",
    "\n",
    "I should really feed this through an **NLP** pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA = df.twitter_screenname.values\n",
    "BB = df.tweet_text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = set( AA.reshape((-1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts =  list(BB.reshape((-1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = [x.replace('\\n',' ') + '\\n' for x in txts if type(x) == str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so here there are a load of texts about Pokemon.\n",
    "\n",
    "- What does this prove? \n",
    "- Why didn't they clean the data?\n",
    "- Do those pesky Russians spies want to prove they are real people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon = [x for x in txts if 'pokemon' in x.lower()]\n",
    "len(pokemon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Keyword arguments `items`, `like`, or `regex` are mutually exclusive",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-257-47e915b441da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tweet text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr'#[Pp]okemon'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/macbuse/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, items, like, regex, axis)\u001b[0m\n\u001b[1;32m   2705\u001b[0m         \u001b[0mnkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2706\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnkw\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2707\u001b[0;31m             raise TypeError('Keyword arguments `items`, `like`, or `regex` '\n\u001b[0m\u001b[1;32m   2708\u001b[0m                             'are mutually exclusive')\n\u001b[1;32m   2709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Keyword arguments `items`, `like`, or `regex` are mutually exclusive"
     ]
    }
   ],
   "source": [
    "import re\n",
    "df.filter(items=['Tweet text'], regex=r'#[Pp]okemon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtag analysis\n",
    "\n",
    "I'm not going to do anything complicated but here we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = file('amalgam_txts.txt','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = hashtag_regex.findall(data)\n",
    "tags = list(set(tags))\n",
    "tags.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinton = [x for x in tags if 'clinton' in x.lower()]\n",
    "clinton = list(set(clinton))\n",
    "clinton.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#associated_words(clinton,['clintons','hilary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill = [x for x in clinton if 'bill' in x.lower()]\n",
    "hil = [x for x in clinton if 'hillary' in x.lower() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have to write a filter to clean things up \n",
    "using a list of **stop words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def associated_words(tags, omit=['']):\n",
    "    stop_words = omit + ['bill','hillary','clinton','2016','16','_'] \n",
    "    old = ' '.join(tags)\n",
    "    stuff = old.lower()\n",
    "    for x in stop_words:\n",
    "        stuff = stuff.replace(x,'')\n",
    "    return set(stuff.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arrest',\n",
       " 'corrupt',\n",
       " 'criminal',\n",
       " 'crooked',\n",
       " 'forpresident',\n",
       " 'indict',\n",
       " 'rotten',\n",
       " 'scripted',\n",
       " 'searchterms',\n",
       " 'theliesof'}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "associated_words(hil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obama = [x for x in tags if 'obama' in x.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'44',\n",
       " '4prison',\n",
       " '7wars',\n",
       " '99daysof',\n",
       " 'admin',\n",
       " 'administration',\n",
       " 'arrest',\n",
       " 'arrestnow',\n",
       " 'b',\n",
       " 'bibivs',\n",
       " 'birdlaunchby',\n",
       " 'birthday',\n",
       " 'birther',\n",
       " 'bomb',\n",
       " 'bye',\n",
       " 'byebye',\n",
       " 'ca',\n",
       " 'care',\n",
       " 'carefail',\n",
       " 'careinthreewords',\n",
       " 'coalition',\n",
       " 'corrupt',\n",
       " 'countdown',\n",
       " 'criesabout',\n",
       " 'crooked',\n",
       " 'dance',\n",
       " 'day',\n",
       " 'defeat',\n",
       " 'fail',\n",
       " 'failed',\n",
       " 'failedhopeandchange',\n",
       " 'failedus',\n",
       " 'family',\n",
       " 'farew',\n",
       " 'farewell',\n",
       " 'farewelladdress',\n",
       " 'farewells',\n",
       " 'finaldays',\n",
       " 'foreignpolicy',\n",
       " 'forprison',\n",
       " 'fuck',\n",
       " 'g',\n",
       " 'gate',\n",
       " 'goodbye',\n",
       " 'goodjob',\n",
       " 'goodriddance',\n",
       " 'growapair',\n",
       " 'happy',\n",
       " 'happybirthday',\n",
       " 'happynday',\n",
       " 'hometown',\n",
       " 'husseininsane',\n",
       " 'ilove',\n",
       " 'imgoingtomissbecause',\n",
       " 'impeach',\n",
       " 'impeachnow',\n",
       " 'imprison',\n",
       " 'indict',\n",
       " 'insult',\n",
       " 'isafraud',\n",
       " 'iscancer',\n",
       " 'isisstra',\n",
       " 'isisstrategies',\n",
       " 'istheproblem',\n",
       " 'istheworstpresidentever',\n",
       " 'jail',\n",
       " 'king',\n",
       " 'knew',\n",
       " 'legacy',\n",
       " 'legacyoffailures',\n",
       " 'lies',\n",
       " 'malia',\n",
       " 'michelle',\n",
       " 'michellemade',\n",
       " 'n',\n",
       " 'nation',\n",
       " 'ncare',\n",
       " 'nextjob',\n",
       " 'no',\n",
       " 'nophone',\n",
       " 'notcare',\n",
       " 'notrade',\n",
       " 'out',\n",
       " 'packyourshit',\n",
       " 'poundsand',\n",
       " 'presidentnotbarry',\n",
       " 'pressconference',\n",
       " 'presser',\n",
       " 'regime',\n",
       " 'repealcare',\n",
       " 'resign',\n",
       " 's',\n",
       " 'samerica',\n",
       " 'sbananarepublic',\n",
       " 'scandals',\n",
       " 'sfarewell',\n",
       " 'sfault',\n",
       " 'shutdown',\n",
       " 'sincestartedtalking',\n",
       " 'sjihad',\n",
       " 'slastday',\n",
       " 'slegacy',\n",
       " 'slushfund',\n",
       " 'soldout',\n",
       " 'speech',\n",
       " 'sswissaccount',\n",
       " 'stop',\n",
       " 'stopyourbombing',\n",
       " 'supporter',\n",
       " 'swishlist',\n",
       " 'team',\n",
       " 'terrorist',\n",
       " 'thankin4words',\n",
       " 'thanks',\n",
       " 'thankyou',\n",
       " 'thankyoumrs',\n",
       " 'thankyous',\n",
       " 'thedestroyer',\n",
       " 'theyears',\n",
       " 'townh',\n",
       " 'townhall',\n",
       " 'trade',\n",
       " 'traitor',\n",
       " 'tweetsliketrump',\n",
       " 'wassmugglingweapons',\n",
       " 'wh',\n",
       " 'whereareyou',\n",
       " 'wheres',\n",
       " 'white',\n",
       " 'world'}"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "associated_words(obama, omit=['obama','barack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1st',\n",
       " '4',\n",
       " '4alls',\n",
       " 'actfor',\n",
       " 'african',\n",
       " 'africanhomelandstates',\n",
       " 'africans',\n",
       " 'allrejects',\n",
       " 'anti',\n",
       " 'antirhetoric',\n",
       " 'antitrumpis',\n",
       " 'bendover',\n",
       " 'black',\n",
       " 'blackpbs',\n",
       " 'blacks',\n",
       " 'bornagain',\n",
       " 'callbank',\n",
       " 'cgi',\n",
       " 'contractwith',\n",
       " 'dad',\n",
       " 'death2',\n",
       " 'deathto',\n",
       " 'decides',\n",
       " 'democratsdestructionof',\n",
       " 'deservesbetter',\n",
       " 'disgraceto',\n",
       " 'divided',\n",
       " 'eagle',\n",
       " 'eagleday',\n",
       " 'energyplan',\n",
       " 'f',\n",
       " 'failedslogans',\n",
       " 'fake',\n",
       " 'falls',\n",
       " 'feminine4trump',\n",
       " 'fi',\n",
       " 'fir',\n",
       " 'firs',\n",
       " 'first',\n",
       " 'flag',\n",
       " 'for',\n",
       " 'fuckingsinrealtime',\n",
       " 'fundamentallychanged',\n",
       " 'getitright',\n",
       " 'godbless',\n",
       " 'gods',\n",
       " 'gophatess',\n",
       " 'gopunfit2leadorgoverns',\n",
       " 'greats',\n",
       " 'grindingdown',\n",
       " 'guns',\n",
       " 'gunsin',\n",
       " 'hates',\n",
       " 'hatess',\n",
       " 'heartassociation',\n",
       " 'hire',\n",
       " 'historyisblack',\n",
       " 'honest',\n",
       " 'horrorstory',\n",
       " 'hostage',\n",
       " 'howtosurvivetrumps',\n",
       " 'idol',\n",
       " 'ilove',\n",
       " 'include',\n",
       " 'inspiring',\n",
       " 'isback',\n",
       " 'isdoomed',\n",
       " 'ismnotglobalism',\n",
       " 'keepbeautiful',\n",
       " 'keepsafeagain',\n",
       " 'lagalaxyvs',\n",
       " 'lefthates',\n",
       " 'letsmakegreat',\n",
       " 'letsmakegreatagain',\n",
       " 'libertyhour',\n",
       " 'made',\n",
       " 'make',\n",
       " 'makeabook',\n",
       " 'makedate',\n",
       " 'makefirst',\n",
       " 'makeg',\n",
       " 'makegr',\n",
       " 'makegre',\n",
       " 'makegreaagain',\n",
       " 'makegreat',\n",
       " 'makegreata',\n",
       " 'makegreatagain',\n",
       " 'makegreatgreatagain',\n",
       " 'makegreenagain',\n",
       " 'makegropeagain',\n",
       " 'makehealthyagain',\n",
       " 'makejimcrowagain',\n",
       " 'makeoneagain',\n",
       " 'makeproudagain',\n",
       " 'makerespectedagain',\n",
       " 'makerichagain',\n",
       " 'makesafeagain',\n",
       " 'makesickagain',\n",
       " 'makestrongagain',\n",
       " 'makeworkagain',\n",
       " 'makinggreatagain',\n",
       " 'masterspbs',\n",
       " 'matters',\n",
       " 'militia',\n",
       " 'miss',\n",
       " 'mr',\n",
       " 'muslims',\n",
       " 'native',\n",
       " 'ninjawarrior',\n",
       " 'norefugeesin',\n",
       " 'obamas',\n",
       " 'ojmadein',\n",
       " 'one',\n",
       " 'patriot',\n",
       " 'people',\n",
       " 'phobia',\n",
       " 'pray4',\n",
       " 'prayfor',\n",
       " 'progressivehateof',\n",
       " 'proud',\n",
       " 'proudtobe',\n",
       " 'rapeseverydays',\n",
       " 'reclaim',\n",
       " 'recyclesday',\n",
       " 'replacethe1partyryanatraitor2weneedourtrumpnow',\n",
       " 'restore',\n",
       " 'rip',\n",
       " 'riseup',\n",
       " 's',\n",
       " 'save',\n",
       " 'saveow',\n",
       " 'savetheworker',\n",
       " 'sfirst',\n",
       " 'shehates',\n",
       " 'signsyouare',\n",
       " 'slivesmatter',\n",
       " 'smerkel',\n",
       " 'sniper',\n",
       " 'spectator',\n",
       " 'spirit',\n",
       " 'struefeelingsabout',\n",
       " 'stupids',\n",
       " 'takeback',\n",
       " 'tellitsgreat',\n",
       " 'terrorist',\n",
       " 'thisisslastchance',\n",
       " 'transformin5words',\n",
       " 'trump',\n",
       " 'trumps',\n",
       " 'uaall',\n",
       " 'un',\n",
       " 'unafy',\n",
       " 'underattack',\n",
       " 'united',\n",
       " 'unitedsfortrump',\n",
       " 'unitedstatesof',\n",
       " 'unitefor',\n",
       " 'ursurystatesof',\n",
       " 'values',\n",
       " 'votetrumpsave',\n",
       " 'wake',\n",
       " 'wakeaup',\n",
       " 'wakeup',\n",
       " 'wasnevergreat',\n",
       " 'wetooare',\n",
       " 'wins',\n",
       " 'won',\n",
       " 'wrongfor',\n",
       " 'wtfin5words',\n",
       " 'yourvote'}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "america = [x for x in tags if 'america' in x.lower()]\n",
    "associated_words(america, omit=['american','america'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
